{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8edd381",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3e3cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# For reproducability.\n",
    "seed = 2003\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45dacc",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f81f99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessments = pd.read_csv(r'..\\..\\anonymisedData\\assessments.csv')\n",
    "courses = pd.read_csv(r'..\\..\\anonymisedData\\courses.csv')\n",
    "studentAssessment = pd.read_csv(r'..\\..\\anonymisedData\\studentAssessment.csv')\n",
    "studentInfo = pd.read_csv(r'..\\..\\anonymisedData\\studentInfo.csv')\n",
    "studentRegistration = pd.read_csv(r'..\\..\\anonymisedData\\studentRegistration.csv')\n",
    "studentVle = pd.read_csv(r'..\\..\\anonymisedData\\studentVle.csv')\n",
    "vle = pd.read_csv(r'..\\..\\anonymisedData\\vle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c44d399",
   "metadata": {},
   "source": [
    "# Generate Dropout Data Based On Module Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c0ff1cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   code_module code_presentation  module_presentation_length  timestamp\n",
      "0          AAA             2013J                         268        268\n",
      "1          AAA             2014J                         269        269\n",
      "2          BBB             2013J                         268        268\n",
      "3          BBB             2014J                         262        262\n",
      "4          BBB             2013B                         240        240\n",
      "5          BBB             2014B                         234        234\n",
      "6          CCC             2014J                         269        269\n",
      "7          CCC             2014B                         241        241\n",
      "8          DDD             2013J                         261        261\n",
      "9          DDD             2014J                         262        262\n",
      "10         DDD             2013B                         240        240\n",
      "11         DDD             2014B                         241        241\n",
      "12         EEE             2013J                         268        268\n",
      "13         EEE             2014J                         269        269\n",
      "14         EEE             2014B                         241        241\n",
      "15         FFF             2013J                         268        268\n",
      "16         FFF             2014J                         269        269\n",
      "17         FFF             2013B                         240        240\n",
      "18         FFF             2014B                         241        241\n",
      "19         GGG             2013J                         261        261\n",
      "20         GGG             2014J                         269        269\n",
      "21         GGG             2014B                         241        241\n"
     ]
    }
   ],
   "source": [
    "# Get module timestamps.\n",
    "module_timestamps = courses.copy()\n",
    "module_timestamps['timestamp'] = module_timestamps['module_presentation_length'] # Set the timestamp here.\n",
    "print(module_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca174a",
   "metadata": {},
   "source": [
    "## VLE Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66122f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with an inner join.\n",
    "vle_df = pd.merge(studentVle, vle, on=['code_module', 'code_presentation', 'id_site'], how='inner')\n",
    "vle_df.drop(columns=['week_from', 'week_to'], inplace=True) # Drop columns.\n",
    "\n",
    "# Filter VLE and assessments.\n",
    "# Filter rows where date is <= timestamp\n",
    "vle_df_custom = vle_df.merge(module_timestamps[['code_module', 'code_presentation', 'timestamp']], on=['code_module', 'code_presentation'], how='left')\n",
    "vle_df_custom = vle_df_custom[vle_df_custom['date'] <= vle_df_custom['timestamp']]\n",
    "\n",
    "# Aggregate total clicks and active days.\n",
    "vle_agg_custom = vle_df_custom.groupby(['code_module', 'code_presentation', 'id_student']).agg(\n",
    "    total_clicks=('sum_click', 'sum'),\n",
    "    num_days_active=('date', 'nunique'),\n",
    ").reset_index()\n",
    "\n",
    "# Add timestamp again.\n",
    "vle_agg_custom = vle_agg_custom.merge(\n",
    "    module_timestamps[['code_module', 'code_presentation', 'timestamp']], \n",
    "    on=['code_module', 'code_presentation'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Normalize active days.\n",
    "vle_agg_custom['days_active_norm'] = vle_agg_custom['num_days_active'] / vle_agg_custom['timestamp']\n",
    "vle_agg_custom['days_active_norm'] = round(vle_agg_custom['days_active_norm'].clip(upper=1), 2)\n",
    "vle_agg_custom = vle_agg_custom.drop(columns=['timestamp', 'num_days_active'])\n",
    "\n",
    "# Get full list of students by module/presentation.\n",
    "student_keys = studentInfo[['code_module', 'code_presentation', 'id_student']].drop_duplicates()\n",
    "\n",
    "# Merge with all students to include those with 0 VLE.\n",
    "vle_agg_custom = student_keys.merge(vle_agg_custom, on=['code_module', 'code_presentation', 'id_student'], how='left')\n",
    "\n",
    "# Fill NaNs for students with no activity.\n",
    "vle_agg_custom['total_clicks'] = vle_agg_custom['total_clicks'].fillna(0)\n",
    "vle_agg_custom['days_active_norm'] = vle_agg_custom['days_active_norm'].fillna(0)\n",
    "\n",
    "# Build the activity click matrix.\n",
    "vle_activity_ohe_custom = pd.pivot_table(\n",
    "    vle_df_custom,\n",
    "    index = ['code_module', 'code_presentation', 'id_student'],\n",
    "    columns = 'activity_type',\n",
    "    values = 'sum_click',\n",
    "    aggfunc = 'sum',\n",
    "    fill_value = 0\n",
    ").reset_index()\n",
    "\n",
    "# Make sure students with no activity are included.\n",
    "vle_activity_ohe_custom = student_keys.merge(\n",
    "    vle_activity_ohe_custom,\n",
    "    on=['code_module', 'code_presentation', 'id_student'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing click values with 0.\n",
    "activity_cols = [col for col in vle_activity_ohe_custom.columns if col not in ['code_module', 'code_presentation', 'id_student']]\n",
    "vle_activity_ohe_custom[activity_cols] = vle_activity_ohe_custom[activity_cols].fillna(0)\n",
    "\n",
    "# One-hot encode clicks by activity type.\n",
    "vle_unique_module_activity_custom = (\n",
    "    vle_df_custom[['code_module', 'activity_type']]\n",
    "    .drop_duplicates()\n",
    "    .assign(is_available=1)\n",
    "    .pivot_table(index='code_module', columns='activity_type', values='is_available', fill_value=0)\n",
    ").reset_index()\n",
    "\n",
    "vle_unique_module_activity_custom.columns = ['code_module'] + [f\"has_{col}\" for col in vle_unique_module_activity_custom.columns[1:]]\n",
    "\n",
    "# Merge vle_unique_module_activity_custom with vle_activity_ohe_custom.\n",
    "vle_activity_features_custom = pd.merge(\n",
    "    vle_activity_ohe_custom,\n",
    "    vle_unique_module_activity_custom,\n",
    "    on='code_module',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge with the previously aggregated VLE dfs.\n",
    "vle_df_custom = pd.merge(\n",
    "    vle_agg_custom,  # total_clicks and num_days_active_norm.\n",
    "    vle_activity_features_custom,\n",
    "    on=['code_module', 'code_presentation', 'id_student'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c7fad",
   "metadata": {},
   "source": [
    "## Student Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "169d2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_reg_and_courses_df = pd.merge(studentRegistration, courses, on=['code_module', 'code_presentation'], how='inner')\n",
    "student_details_df = pd.merge(student_reg_and_courses_df, studentInfo, on=['code_module', 'code_presentation', 'id_student'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc76099",
   "metadata": {},
   "source": [
    "## Assessment Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4639244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing exam dates with the module_presentation_length date.\n",
    "assessments.loc[assessments['date'].isna(), 'date'] = assessments.loc[assessments['date'].isna()].merge(\n",
    "    courses[['code_module', 'code_presentation', 'module_presentation_length']],\n",
    "    on=['code_module', 'code_presentation'],\n",
    "    how='left'\n",
    ")['module_presentation_length'].values\n",
    "\n",
    "assessment_df = pd.merge(assessments, studentAssessment, on=['id_assessment'], how='inner')\n",
    "\n",
    "# Rearrange column names.\n",
    "assessment_df = assessment_df[['id_student', 'code_module', 'code_presentation', 'id_assessment', 'assessment_type', 'date', 'date_submitted', 'weight', 'is_banked', 'score']]\n",
    "assessment_df = assessment_df.rename(columns={'date': 'date_due'}) # Rename 'date' to 'date_due'\n",
    "\n",
    "# Filter rows where date_due is <= timestamp.\n",
    "assessment_df_custom = assessment_df.merge(module_timestamps[['code_module', 'code_presentation', 'timestamp']], on=['code_module', 'code_presentation'], how='left')\n",
    "assessment_df_custom = assessment_df_custom[assessment_df_custom['date_due'] <= assessment_df_custom['timestamp']]\n",
    "assessment_results_df_custom = assessment_df_custom.copy() # Make a copy of dataset.\n",
    "\n",
    "## Weighted Score ##\n",
    "# For each assessment due before timestamp.\n",
    "assessment_due = assessment_df_custom[['code_module', 'code_presentation', 'id_assessment', 'weight', 'assessment_type', 'date_due']].drop_duplicates()\n",
    "\n",
    "# Cross join students and assessments by module/presentation.\n",
    "students_assessments = student_keys.merge(assessment_due, on=['code_module', 'code_presentation'], how='left')\n",
    "\n",
    "# Merge with actual student submissions.\n",
    "students_assessments = students_assessments.merge(\n",
    "    studentAssessment[['id_student', 'id_assessment', 'date_submitted', 'is_banked', 'score']],\n",
    "    on=['id_student', 'id_assessment'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing scores with 0 (for not submitted).\n",
    "students_assessments['score'] = students_assessments['score'].fillna(0)\n",
    "\n",
    "# Compute total weight per student/module (based on all assessments that were due)\n",
    "total_weight_df = students_assessments.groupby(['id_student', 'code_module', 'code_presentation'])['weight'].sum().reset_index(name='total_weight')\n",
    "\n",
    "# Merge total weight back.\n",
    "students_assessments = students_assessments.merge(total_weight_df, on=['id_student', 'code_module', 'code_presentation'], how='left')\n",
    "\n",
    "# Compute weighted score per assessment.\n",
    "students_assessments['weighted_score_component'] = (\n",
    "    (students_assessments['weight'] / students_assessments['total_weight']) *\n",
    "    students_assessments['score']\n",
    ")\n",
    "\n",
    "# Final weighted score per student/module.\n",
    "assessment_results_df_custom = students_assessments.groupby(['id_student', 'code_module', 'code_presentation'])['weighted_score_component'].sum().reset_index(name='weighted_score')\n",
    "assessment_results_df_custom['weighted_score'] = assessment_results_df_custom['weighted_score'].round(2)\n",
    "\n",
    "## Banked Rate ##\n",
    "# Count total assessments per student per module presentation.\n",
    "total_assessments_custom = assessment_df_custom.groupby(['id_student', 'code_module', 'code_presentation'])['is_banked'].count().reset_index()\n",
    "total_assessments_custom = total_assessments_custom.rename(columns={'is_banked': 'total_assessments_custom'})\n",
    "\n",
    "# Count number of banked assessments (is_banked == 1).\n",
    "banked_assessments = assessment_df_custom[assessment_df_custom['is_banked'] == 1].groupby(\n",
    "    ['id_student', 'code_module', 'code_presentation'])['is_banked'].count().reset_index()\n",
    "banked_assessments = banked_assessments.rename(columns={'is_banked': 'banked_assessments'})\n",
    "\n",
    "# Merge the two.\n",
    "banked_rate_df_custom = total_assessments_custom.merge(\n",
    "    banked_assessments, \n",
    "    on=['id_student', 'code_module', 'code_presentation'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN banked counts with 0 and compute ratio.\n",
    "banked_rate_df_custom['banked_assessments'] = banked_rate_df_custom['banked_assessments'].fillna(0)\n",
    "banked_rate_df_custom['banked_rate'] = round(banked_rate_df_custom['banked_assessments'] / banked_rate_df_custom['total_assessments_custom'], 2)\n",
    "\n",
    "# Drop helper columns.\n",
    "banked_rate_df_custom = banked_rate_df_custom.drop(columns=['total_assessments_custom', 'banked_assessments'])\n",
    "\n",
    "# Merge the banked_rate into assessment_results_df_custom.\n",
    "assessment_results_df_custom = assessment_results_df_custom.merge(\n",
    "    banked_rate_df_custom,\n",
    "    on=['id_student', 'code_module', 'code_presentation'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "## Late Submission Rate ##\n",
    "late_submission_df_custom = assessment_df_custom.copy()\n",
    "late_submission_df_custom[(late_submission_df_custom['assessment_type'] == 'Exam') & (late_submission_df_custom['date_submitted'] > late_submission_df_custom['date_due'])]\n",
    "\n",
    "# Calculate late submission: submission is late if date_submitted > date_due, and date_due is not missing.\n",
    "late_submission_df_custom['late_submission'] = ((late_submission_df_custom['date_submitted'] > late_submission_df_custom['date_due']) & late_submission_df_custom['date_due'].notna())\n",
    "\n",
    "# Group to get total late submissions per student/module.\n",
    "late_counts = late_submission_df_custom.groupby(['id_student', 'code_module', 'code_presentation'])['late_submission'].sum().reset_index(name='late_count')\n",
    "\n",
    "# Get total assessments submitted per student/module.\n",
    "total_per_student_submission_counts_custom = late_submission_df_custom.groupby(['id_student', 'code_module', 'code_presentation']).size().reset_index(name='total_submitted')\n",
    "late_rate_df_custom = pd.merge(late_counts, total_per_student_submission_counts_custom, on=['id_student', 'code_module', 'code_presentation']) # Merge the late counts and total counts dfs.\n",
    "late_rate_df_custom['late_rate'] = round(late_rate_df_custom['late_count'] / late_rate_df_custom['total_submitted'], 2) # Calculate late submission rate and round it to 2 decimal places.\n",
    "late_rate_df_custom.drop(columns=['late_count', 'total_submitted'], inplace=True) # Drop helper columns.\n",
    "\n",
    "## Fail Rate ##\n",
    "students_in_module_custom = assessment_df_custom[['id_student', 'code_module', 'code_presentation']].drop_duplicates()\n",
    "all_assessments_custom = assessment_df_custom[['id_assessment', 'code_module', 'code_presentation']].drop_duplicates()\n",
    "rows = []\n",
    "\n",
    "# Iterate over each module/presentation group separately.\n",
    "for (module, presentation), students_grp in students_in_module_custom.groupby(['code_module', 'code_presentation']):\n",
    "    assessments_grp = all_assessments_custom[\n",
    "        (all_assessments_custom['code_module'] == module) & \n",
    "        (all_assessments_custom['code_presentation'] == presentation)\n",
    "    ]\n",
    "    for student, assessment in itertools.product(students_grp['id_student'], assessments_grp['id_assessment']):\n",
    "        rows.append({\n",
    "            'code_module': module,\n",
    "            'code_presentation': presentation,\n",
    "            'id_student': student,\n",
    "            'id_assessment': assessment\n",
    "        })\n",
    "\n",
    "cartesian_df_custom = pd.DataFrame(rows)\n",
    "\n",
    "# Merge the full student assessment pairs with actual scores (NaN means not submitted).\n",
    "merged_student_assessment_pairs = cartesian_df_custom.merge(\n",
    "    assessment_df_custom[['id_student', 'id_assessment', 'score']],\n",
    "    on=['id_student', 'id_assessment'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Mark fail if score < 40 or score is missing (NaN).\n",
    "merged_student_assessment_pairs['fail'] = merged_student_assessment_pairs['score'].isna() | (merged_student_assessment_pairs['score'] < 40)\n",
    "\n",
    "# Calculate fail counts and total assessments per student/module.\n",
    "fail_rate_df_custom = merged_student_assessment_pairs.groupby(['id_student', 'code_module', 'code_presentation']).agg(\n",
    "    total_assessments=('fail', 'count'),\n",
    "    total_fails=('fail', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate fail rate.\n",
    "fail_rate_df_custom['fail_rate'] = (fail_rate_df_custom['total_fails'] / fail_rate_df_custom['total_assessments']).round(2)\n",
    "fail_rate_df_custom = fail_rate_df_custom.drop(columns=['total_assessments', 'total_fails'])\n",
    "\n",
    "## Merge Assessment Tables ##\n",
    "student_assessments_df_custom = pd.merge(assessment_results_df_custom, late_rate_df_custom, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "student_assessments_df_custom = pd.merge(student_assessments_df_custom, fail_rate_df_custom, on=['id_student', 'code_module', 'code_presentation'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b8e25e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_student</th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>weighted_score</th>\n",
       "      <th>banked_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3733</td>\n",
       "      <td>DDD</td>\n",
       "      <td>2013J</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6516</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2014J</td>\n",
       "      <td>63.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8462</td>\n",
       "      <td>DDD</td>\n",
       "      <td>2013J</td>\n",
       "      <td>17.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8462</td>\n",
       "      <td>DDD</td>\n",
       "      <td>2014J</td>\n",
       "      <td>21.50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11391</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>82.40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32588</th>\n",
       "      <td>2702660</td>\n",
       "      <td>FFF</td>\n",
       "      <td>2014J</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32589</th>\n",
       "      <td>2707979</td>\n",
       "      <td>DDD</td>\n",
       "      <td>2013B</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32590</th>\n",
       "      <td>2710343</td>\n",
       "      <td>DDD</td>\n",
       "      <td>2013B</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32591</th>\n",
       "      <td>2710343</td>\n",
       "      <td>DDD</td>\n",
       "      <td>2014B</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32592</th>\n",
       "      <td>2716795</td>\n",
       "      <td>DDD</td>\n",
       "      <td>2014J</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32593 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_student code_module code_presentation  weighted_score  banked_rate\n",
       "0            3733         DDD             2013J            0.00          NaN\n",
       "1            6516         AAA             2014J           63.50          0.0\n",
       "2            8462         DDD             2013J           17.45          0.0\n",
       "3            8462         DDD             2014J           21.50          1.0\n",
       "4           11391         AAA             2013J           82.40          0.0\n",
       "...           ...         ...               ...             ...          ...\n",
       "32588     2702660         FFF             2014J            0.00          NaN\n",
       "32589     2707979         DDD             2013B            0.00          NaN\n",
       "32590     2710343         DDD             2013B            0.00          NaN\n",
       "32591     2710343         DDD             2014B            0.00          NaN\n",
       "32592     2716795         DDD             2014J            0.00          NaN\n",
       "\n",
       "[32593 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessment_results_df_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228b537",
   "metadata": {},
   "source": [
    "## Final Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c46b5e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df_custom = pd.merge(student_details_df, vle_df_custom, on=['id_student', 'code_module', 'code_presentation'], how='left')\n",
    "student_df_custom = pd.merge(student_df_custom, student_assessments_df_custom, on=['id_student', 'code_module', 'code_presentation'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca932c",
   "metadata": {},
   "source": [
    "# Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "95568457",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date Registration ##\n",
    "median_reg_date = student_df_custom.date_registration.median() # Get median registration date.\n",
    "# Replace null values with date unregistration to the median date.\n",
    "student_df_custom['date_registration'] = np.where((student_df_custom['date_registration'].isnull()), \n",
    "                                                    student_df_custom['date_unregistration'] + median_reg_date,\n",
    "                                                    student_df_custom['date_registration'])\n",
    "\n",
    "# Replace remaining null values with -57 (with null date_unregistration).\n",
    "student_df_custom['date_registration'] = np.where( (student_df_custom['date_registration'].isnull()), median_reg_date, student_df_custom['date_registration'])\n",
    "\n",
    "## Gender and Disability ##\n",
    "student_df_custom['gender'] = student_df_custom['gender'].map({'M': 1, 'F': 0}) # Convert gender: M = 1, F = 0.\n",
    "student_df_custom['disability'] = student_df_custom['disability'].map({'Y': 1, 'N': 0}) # Convert disability: Y = 1, N = 0.\n",
    "\n",
    "## Highest Education ##\n",
    "he_encoding = {\n",
    "    'No Formal quals': 0,\n",
    "    'Lower Than A Level': 1,\n",
    "    'A Level or Equivalent': 2,\n",
    "    'HE Qualification': 3,\n",
    "    'Post Graduate Qualification': 4\n",
    "}\n",
    "student_df_custom['highest_education'] = student_df_custom['highest_education'].map(he_encoding).astype(int)\n",
    "\n",
    "## Age Band ##\n",
    "age_mapping = {\n",
    "    '0-35': 0,\n",
    "    '35-55': 1,\n",
    "    '55<=': 2\n",
    "}\n",
    "student_df_custom['age_band'] = student_df_custom['age_band'].map(age_mapping).astype(int)\n",
    "\n",
    "## Final Result ##\n",
    "final_result_mapping = {\n",
    "    'Distinction': 3,\n",
    "    'Pass': 2,\n",
    "    'Fail': 1,\n",
    "    'Withdrawn': 0\n",
    "}\n",
    "student_df_custom['final_result'] = student_df_custom['final_result'].map(final_result_mapping).astype(int)\n",
    "\n",
    "## Total Clicks ##\n",
    "# Calculate mean 'total_clicks' for students who passed and have non-null `total_clicks`.\n",
    "mean_total_clicks_for_pass_custom = int(student_df_custom[(student_df_custom['final_result'] == 2) & (student_df_custom['total_clicks'].notna())]['total_clicks'].mean())\n",
    "\n",
    "# Impute missing `total_clicks` for students who have passed.\n",
    "student_df_custom.loc[(student_df_custom['final_result'] == 2) & (student_df_custom['total_clicks'].isna()), 'total_clicks'] = mean_total_clicks_for_pass_custom\n",
    "\n",
    "## Banked Rate ##\n",
    "student_df_custom['banked_rate'] = student_df_custom['banked_rate'].fillna(0)\n",
    "\n",
    "## Weighted Score ##\n",
    "# Calculate and store the mean pass score.\n",
    "mean_pass_score_custom = round(student_df_custom[(student_df_custom['final_result'] == 2) & (student_df_custom['weighted_score'].notna())]['weighted_score'].mean(), 2)\n",
    "\n",
    "# Impute the mean pass score to the three students who have passed but have null weighted scores.\n",
    "student_df_custom.loc[(student_df_custom['final_result'] == 2) & (student_df_custom['weighted_score'].isna()),'weighted_score'] = round(mean_pass_score_custom, 2)\n",
    "\n",
    "# For the Failed/Withdrawn students, the weighted score will be set to 0.\n",
    "student_df_custom['weighted_score'] = student_df_custom['weighted_score'].fillna(0)\n",
    "\n",
    "## Late and Fail Rate ##\n",
    "### Late Rate ###\n",
    "# Impute mean late_rate for passed students missing it.\n",
    "mean_pass_late_rate_custom = round(student_df_custom.loc[(student_df_custom['final_result'] == 2) & (student_df_custom['late_rate'].notna()), 'late_rate'].mean(), 2)\n",
    "student_df_custom.loc[(student_df_custom['final_result'] == 2) & (student_df_custom['late_rate'].isna()), 'late_rate'] = mean_pass_late_rate_custom\n",
    "\n",
    "### Fail Rate ###\n",
    "# Impute mean fail_rate for passed students missing it.\n",
    "mean_pass_fail_rate_custom = round(student_df_custom.loc[(student_df_custom['final_result'] == 2) & (student_df_custom['fail_rate'].notna()), 'fail_rate'].mean(), 2)\n",
    "student_df_custom.loc[(student_df_custom['final_result'] == 2) & (student_df_custom['fail_rate'].isna()), 'fail_rate'] = mean_pass_fail_rate_custom\n",
    "\n",
    "# Fill remaining missing late_rate and fail_rate with 0.\n",
    "student_df_custom['late_rate'] = student_df_custom['late_rate'].fillna(1)\n",
    "student_df_custom['fail_rate'] = student_df_custom['fail_rate'].fillna(1)\n",
    "\n",
    "## IMD Band ##\n",
    "imd_mapping = {\n",
    "    '0-10%': 0,\n",
    "    '10-20': 1,\n",
    "    '20-30%': 2,\n",
    "    '30-40%': 3,\n",
    "    '40-50%': 4,\n",
    "    '50-60%': 5,\n",
    "    '60-70%': 6,\n",
    "    '70-80%': 7,\n",
    "    '80-90%': 8,\n",
    "    '90-100%': 9\n",
    "}\n",
    "student_df_custom['imd_band'] = student_df_custom['imd_band'].map(imd_mapping)\n",
    "\n",
    "# Prepare the data.\n",
    "features = ['region', 'age_band', 'highest_education', 'gender', 'disability', 'final_result']\n",
    "bayesian_imd_df = student_df_custom[features + ['imd_band']].copy()\n",
    "bayesian_imd_df = bayesian_imd_df.dropna(subset=features) # Drop rows with missing values in the features\n",
    "\n",
    "# Separate rows with known and missing imd_band.\n",
    "train_imd_df = bayesian_imd_df[bayesian_imd_df['imd_band'].notnull()]\n",
    "predict_imd_df = bayesian_imd_df[bayesian_imd_df['imd_band'].isnull()]\n",
    "\n",
    "# Define columns to encode.\n",
    "onehot_imd_cols = ['region', 'gender']\n",
    "ordinal_imd_cols = ['age_band', 'highest_education', 'disability', 'final_result']\n",
    "\n",
    "# Set up column transformer.\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'), onehot_imd_cols),\n",
    "        ('ordinal', OrdinalEncoder(), ordinal_imd_cols)\n",
    "    ])\n",
    "\n",
    "# Fit on training data and transform both train and predict sets.\n",
    "X_train = preprocessor.fit_transform(train_imd_df[features])\n",
    "X_predict = preprocessor.transform(predict_imd_df[features])\n",
    "y_train = train_imd_df['imd_band'].astype(float)\n",
    "\n",
    "# Initiate and fit the bayesian model.\n",
    "bayesian_imd_model = BayesianRidge()\n",
    "bayesian_imd_model.fit(X_train, y_train)\n",
    "\n",
    "predicted_imd = bayesian_imd_model.predict(X_predict).round().clip(0, 9).astype(int) # Predict missing imd values.\n",
    "student_df_custom.loc[student_df_custom['imd_band'].isnull(), 'imd_band'] = predicted_imd # Impute the imd predictions into the custom dataset.\n",
    "\n",
    "## Date Unregistration ##\n",
    "student_df_custom.drop(columns='date_unregistration', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92130847",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df_custom.to_csv('student_df_full.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
